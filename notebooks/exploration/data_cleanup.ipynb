{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old_positions_data.xlsx to csv cleanup:\n",
    "This process is performed in order to prepare the data for the transformation across the timeline, so the warehouse will represent as best possible to how it looked like on the 1.1.2021.\n",
    "\n",
    "The following steps are performed:\n",
    "1. Format dates to match the activity_data table.\n",
    "2. Remove rows which contain items in problematic locations (`'sort', 'cd', 'kir', 'flawed', 'rl'`).\n",
    "3. Merge the old_positions_data table with the item sized and cell sizes.\n",
    "4. Fill in the volumes for items which are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data_route = '../data/raw/'\n",
    "old_positions_data = pd.read_excel(f'{raw_data_route}old_positions_data.xlsx', sheet_name=\"position\")\n",
    "item_sizes = pd.read_excel(f'{raw_data_route}item_sizes.xlsx', sheet_name=\"Sheet1\")\n",
    "# read the 'Sheet1' from the excel file 'cell_sizes.xlsx' into a DataFrame, and make sure that the 'location' and 'aisle',  are objects:\n",
    "cell_sizes = pd.read_excel(f'{raw_data_route}cell_sizes.xlsx', sheet_name=\"Sheet1\", dtype={'location': object, 'aisle': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the old_positions_datas worksheet:\n",
    "column_names = old_positions_data.columns\n",
    "date_columns = [name for name in column_names if 'date' in name]\n",
    "date_columns\n",
    "old_positions_data[date_columns] = pd.to_datetime(old_positions_data[date_columns].stack()).unstack()  # Stack and unstack are needed because to_datetime works with Series but not with DataFrame.\n",
    "old_positions_data[['quantity counted']] = old_positions_data[['quantity counted']].astype(float)\n",
    "# turn all the old_positions_data columns which contain strings to uppercase:\n",
    "old_positions_data = old_positions_data.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)\n",
    "old_positions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all items which aren't placed on shelves in an indexed pattern:\n",
    "problematic_location_names = ['sort', 'cd', 'kir', 'flawed', 'rl']\n",
    "for name in problematic_location_names: # Remove all problematic places from the DF so we can work with items we can manage\n",
    "  old_positions_data = old_positions_data[~old_positions_data.location.str.contains(name, case=False)]\n",
    "old_positions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sizes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_positions_data_with_item_sizes = pd.merge(old_positions_data, item_sizes, how='left', on='id')\n",
    "old_positions_data_with_item_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the united_old_positions_data with the cell_sizes worksheet, using the 'location' column as the key:\n",
    "united_old_positions_data = pd.merge(old_positions_data_with_item_sizes.drop(labels=['aisle'], axis=1), cell_sizes, how='left', on='location')\n",
    "united_old_positions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the number of empty values in the 'volume' column:\n",
    "united_old_positions_data['volume'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the united_old_positions_data, select only the rows which have a NaN in the 'volume' column:\n",
    "# then calculate the missing values using the following logic:\n",
    "# if there is more than one row with the same 'location' and 'aisle' values, then make the volume equal to the corresponding 'cubic' value in the cell_sizes worksheet divided by the number of rows with the same 'location' and 'aisle' values:\n",
    "# if the 'quantity counted' cell is 1.0, then make the volume equal to the corresponding 'cubic' value in the cell_sizes worksheet:\n",
    "# if the 'quantity counted' cell is greater than 1.0, then make the volume equal to the corresponding 'cubic' value in the cell_sizes worksheet divided by the 'quantity counted' value:\n",
    "def calculate_volume(row):\n",
    "  if pd.isna(row['volume']):\n",
    "    if row['quantity counted'] == 1.0:\n",
    "      return row['cubic']\n",
    "    else:\n",
    "      return row['cubic'] / row['quantity counted']\n",
    "  else:\n",
    "    return row['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the calculate_volume function on the united_old_positions_data DataFrame:\n",
    "united_old_positions_data['volume'] = united_old_positions_data.apply(calculate_volume, axis=1)\n",
    "# Check for the number of empty values in the 'volume' column, post function application:\n",
    "united_old_positions_data['volume'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_old_positions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_old_positions_data[united_old_positions_data['location'] == '40260901'].sort_values(by=['symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the united_old_positions_data DataFrame and group it by the 'location' column, then count how many rows are in each group:\n",
    "grouped_old_positions_data = united_old_positions_data[['id', 'location']].groupby('location').count().sort_values(by=['id'], ascending=False)\n",
    "# show only the rows from grouped_old_positions_data with a count greater than 1:\n",
    "grouped_old_positions_data[grouped_old_positions_data['id'] > 50]\n",
    "# create a plot showing the distribution of the grouped_old_positions_data DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many unique 'location' values are in the united_old_positions_data DataFrame:\n",
    "united_old_positions_data['location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_positions_data['location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sizes.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many values are overlapping between the old_positions_data 'location' and cell_sizes 'location' columns:\n",
    "len(set(old_positions_data['location'].unique()).intersection(set(cell_sizes['location'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13483-5139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows from the old_positions_data DataFrame where the 'aisle' column is equal to 10 or 11:\n",
    "old_positions_data[(old_positions_data['aisle'] == 10) | (old_positions_data['aisle'] == 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in united_old_positions_data DataFrame, count for each 'id' how many different 'location' values there are:\n",
    "united_old_positions_data[['id', 'location']].groupby('id').nunique().sort_values(by=['location'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from united_old_positions_data get all rows which have an 'id' of 'AAAAA-28953':\n",
    "united_old_positions_data[united_old_positions_data['id'] == 'AAAAA-28953']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
